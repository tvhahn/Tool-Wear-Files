{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from functions import (\n",
    "    under_over_sampler,\n",
    "    classifier_train,\n",
    "    classifier_train_manual,\n",
    "    make_generic_df,\n",
    "    get_xy_from_df,\n",
    "    plot_precision_recall_vs_threshold,\n",
    "    plot_precision_vs_recall,\n",
    ")\n",
    "\n",
    "from classification_methods import (\n",
    "    random_forest_classifier,\n",
    "    knn_classifier,\n",
    "    # logistic_regression,\n",
    "    # sgd_classifier,\n",
    "    # ridge_classifier,\n",
    "    # svm_classifier,\n",
    "    # gaussian_nb_classifier,\n",
    "    xgboost_classifier,\n",
    ")\n",
    "\n",
    "# stop warnings from sklearn\n",
    "# https://stackoverflow.com/questions/32612180/eliminating-warnings-from-scikit-learn\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "list(range(1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL PARAMETERS\n",
    "\n",
    "# select model by commenting/un-commenting classifier\n",
    "classifier_list_all = [\n",
    "    random_forest_classifier,\n",
    "#     knn_classifier,\n",
    "#     logistic_regression,\n",
    "#     sgd_classifier,\n",
    "#     ridge_classifier,\n",
    "#     svm_classifier,\n",
    "#     gaussian_nb_classifier,\n",
    "#     xgboost_classifier,\n",
    "]\n",
    "\n",
    "\n",
    "# select over/under-sampling method\n",
    "over_under_sampling_methods = [\n",
    "#     \"random_over\",\n",
    "    \"random_under\",\n",
    "#     \"random_under_bootstrap\",\n",
    "#     \"smote\",\n",
    "#     \"adasyn\",\n",
    "#     None,\n",
    "]\n",
    "\n",
    "# select which indices to use\n",
    "index_list = [\n",
    "#     list(range(0, 10)),\n",
    "#     list(range(1, 10)),\n",
    "#     list(range(1, 9)),\n",
    "    list(range(1, 8)),\n",
    "#     list(range(2, 8)),\n",
    "#     list(range(3, 7)),\n",
    "#     list(range(2, 9)),\n",
    "#     list(range(2, 10)),\n",
    "]\n",
    "\n",
    "# select the scaler method\n",
    "scaler_methods = [\n",
    "#     \"standard\", \n",
    "    \"min_max\"\n",
    "]\n",
    "\n",
    "# select the imbalance ratio\n",
    "imbalance_ratios = [\n",
    "#     0.1,\n",
    "    0.5,\n",
    "#     0.8,\n",
    "#     1\n",
    "]\n",
    "\n",
    "# select if the feature set is averaged or not\n",
    "average_across_indices = [\n",
    "    True,\n",
    "#     False\n",
    "]\n",
    "\n",
    "# the integer that is used as the random number in the classifier\n",
    "# parameter sampler\n",
    "parameter_sampler_int = [\n",
    "    11475, 11\n",
    "]\n",
    "\n",
    "# features used in model (includes 'failed' column, but this is dropped, don't worry)\n",
    "feat_list = ['rms_current','failed']\n",
    "\n",
    "# other default parameters that do not need to be touched\n",
    "tool_list_all = [54]\n",
    "tool_list_some = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold splits\n",
    "train_fold_1 = [\n",
    "    \"2018-11-21\", \n",
    "    \"2019-01-25\", \n",
    "    \"2019-01-28\", # failures\n",
    "    \"2019-11-27\", # failures\n",
    "    \"2019-01-23\", # failures, from Jan without speed\n",
    "    \"2019-05-03\",\n",
    "    \"2019-09-11\", # failures\n",
    "    \"2019-09-13\",\n",
    "    ]\n",
    "\n",
    "train_fold_2 = [\n",
    "    \"2019-01-29\", # failures\n",
    "    \"2019-01-30\", # failures\n",
    "    \"2019-02-01\",\n",
    "    \"2019-02-08\", # failures\n",
    "    \"2019-09-10\",\n",
    "    \"2019-09-12\",\n",
    "    \"2018-11-20\",\n",
    "    \"2019-02-11\",\n",
    "    \"2019-01-24\", # i forgot this one earlier\n",
    "    \"2019-05-04\",\n",
    "    \"2018-11-16\",\n",
    "    \"2018-11-19\",\n",
    "]\n",
    "\n",
    "train_fold_3 = [\n",
    "    \"2019-02-04\", # failures\n",
    "    \"2019-02-05\", \n",
    "    \"2019-02-07\", # failures\n",
    "    \"2019-05-06\",\n",
    "    \"2019-01-22\", # from Jan without speed \n",
    "    \"2018-10-23\",\n",
    "    \"2018-11-15\", # failures \n",
    "    ]\n",
    "\n",
    "train_folds = [train_fold_1, train_fold_2, train_fold_3]\n",
    "train_dates_all = [date for sublist in train_folds for date in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder = Path(\n",
    "    \"/home/tim/Documents/Checkfluid-Project/data/processed/_tables/low_levels_labels_created_2020-03-11\"\n",
    ")\n",
    "\n",
    "file = file_folder / \"low_level_labels_created_2020.03.11_v3_updated_2020.08.06.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# sort the values by date and index so that it is reproducible\n",
    "df = df.sort_values(by=[\"unix_date\", \"tool\", \"index\"])\n",
    "\n",
    "# replace NaN's in failed columns with 0\n",
    "df[\"failed\"].fillna(\n",
    "    0, inplace=True, downcast=\"int\"\n",
    ")  # replace NaN in 'failed' col with 0\n",
    "\n",
    "# function to convert pandas column to datetime format\n",
    "def convert_to_datetime(cols):\n",
    "    unix_date = cols[0]\n",
    "    value = datetime.fromtimestamp(unix_date)\n",
    "    return value\n",
    "\n",
    "\n",
    "# apply 'date_ymd' column to dataframe\n",
    "df[\"date\"] = df[[\"unix_date\"]].apply(convert_to_datetime, axis=1)\n",
    "# convert to a period, and then string\n",
    "df[\"date_ymd\"] = pd.to_datetime(df[\"date\"], unit=\"s\").dt.to_period(\"D\").astype(str)\n",
    "\n",
    "\n",
    "# create train set\n",
    "df_train = df[df[\"date_ymd\"].isin(train_dates_all)].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sample_dict = {\n",
    "    \"no_tools\": [0], # only select one tool (tool 54)\n",
    "    \"classifier_used\": classifier_list_all,\n",
    "    \"average_across_index\": average_across_indices,\n",
    "    \"uo_method\": over_under_sampling_methods,\n",
    "    \"scaler_method\": scaler_methods,\n",
    "    \"parameter_sampler_random_int\": parameter_sampler_int,\n",
    "    \"imbalance_ratio\": imbalance_ratios,\n",
    "    \"index_list\": index_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_iterations = 2\n",
    "sampler_seed = 1\n",
    "\n",
    "# generate the list of parameters to sample over\n",
    "p_list = list(\n",
    "    ParameterSampler(\n",
    "        parameters_sample_dict, n_iter=no_iterations, random_state=sampler_seed\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'uo_method': 'random_under',\n",
       "  'scaler_method': 'min_max',\n",
       "  'parameter_sampler_random_int': 11475,\n",
       "  'no_tools': 0,\n",
       "  'index_list': [1, 2, 3, 4, 5, 6, 7],\n",
       "  'imbalance_ratio': 0.5,\n",
       "  'classifier_used': <function classification_methods.random_forest_classifier(parameter_sampler_random_int)>,\n",
       "  'average_across_index': True},\n",
       " {'uo_method': 'random_under',\n",
       "  'scaler_method': 'min_max',\n",
       "  'parameter_sampler_random_int': 11,\n",
       "  'no_tools': 0,\n",
       "  'index_list': [1, 2, 3, 4, 5, 6, 7],\n",
       "  'imbalance_ratio': 0.5,\n",
       "  'classifier_used': <function classification_methods.random_forest_classifier(parameter_sampler_random_int)>,\n",
       "  'average_across_index': True}]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5551\n",
      "too many values to unpack (expected 3)\n",
      "#!#!#!#!#! SKIPPING\n",
      "5551\n",
      "too many values to unpack (expected 3)\n",
      "#!#!#!#!#! SKIPPING\n"
     ]
    }
   ],
   "source": [
    "for k, p in enumerate(p_list):\n",
    "\n",
    "    # set random.seed\n",
    "    random.seed(p[\"parameter_sampler_random_int\"])\n",
    "\n",
    "    # get specific parameters\n",
    "    clf_name = str(p[\"classifier_used\"]).split(\" \")[1]\n",
    "\n",
    "    tool_list = sorted(\n",
    "        random.sample(tool_list_some, p[\"no_tools\"])\n",
    "        + [54])\n",
    "\n",
    "\n",
    "    indices_to_keep = p[\"index_list\"]\n",
    "    to_avg = p[\"average_across_index\"]\n",
    "    uo_method = p[\"uo_method\"]\n",
    "\n",
    "    # if svm, need to prevent too large a dataset, thus will only use undersampling\n",
    "    if clf_name == \"svm_classifier\":\n",
    "        uo_method = random.sample([\"random_under\", \"random_under_bootstrap\"], 1)\n",
    "\n",
    "    imbalance_ratio = p[\"imbalance_ratio\"]\n",
    "    scaler_method = p[\"scaler_method\"]\n",
    "    parameter_sampler_random_int = p[\"parameter_sampler_random_int\"]\n",
    "    clf_function = p[\"classifier_used\"]\n",
    "\n",
    "    # build dictionary to store parameter results and other info\n",
    "    parameter_values = {\n",
    "        \"clf_name\": clf_name,\n",
    "        \"tool_list\": tool_list,\n",
    "        \"feat_list\": feat_list,\n",
    "        \"indices_to_keep\": indices_to_keep,\n",
    "        \"info_no_samples\": None,\n",
    "        \"info_no_failures\": None,\n",
    "        \"info_no_feat\": len(feat_list),\n",
    "        \"to_average\": to_avg,\n",
    "        \"uo_method\": uo_method,\n",
    "        \"imbalance_ratio\": imbalance_ratio,\n",
    "        \"scaler_method\": scaler_method,\n",
    "        \"parameter_sampler_seed\": parameter_sampler_random_int,\n",
    "        \"initial_script_seed\": sampler_seed,\n",
    "    }\n",
    "\n",
    "\n",
    "    # prepare the data table\n",
    "    X_train, y_train, df_ymd_only = get_xy_from_df(\n",
    "        df_train,\n",
    "        tool_list=tool_list,\n",
    "        indices_to_keep=indices_to_keep,\n",
    "        to_average=to_avg,\n",
    "        generic_feat_list=feat_list,\n",
    "    )\n",
    "\n",
    "    # check if empty X_train\n",
    "    len_data = len(y_train)\n",
    "    print(len_data)\n",
    "    # check if not enough labels in y_train\n",
    "    no_label_failed = np.sum(y_train)\n",
    "\n",
    "    seed_indexer = 0\n",
    "#     while len_data < 20 or no_label_failed < 15:\n",
    "#         random.seed(p[\"parameter_sampler_random_int\"] + seed_indexer)\n",
    "#         tool_list = sorted(\n",
    "#             random.sample(tool_list_some, p[\"no_tools\"])\n",
    "#             + random.sample([54], random.randint(1, 2))\n",
    "#         )\n",
    "\n",
    "#         X_train, y_train, df_ymd_only = get_xy_from_df(\n",
    "#             df_train,\n",
    "#             tool_list=tool_list,\n",
    "#             indices_to_keep=indices_to_keep,\n",
    "#             to_average=to_avg,\n",
    "#             generic_feat_list=feat_list,\n",
    "#         )\n",
    "\n",
    "#         parameter_values[\"tool_list\"] = tool_list\n",
    "\n",
    "#         len_data = len(y_train)\n",
    "#         no_label_failed = np.sum(y_train)\n",
    "#         seed_indexer += 1\n",
    "\n",
    "    parameter_values[\"info_no_samples\"] = len_data\n",
    "    parameter_values[\"info_no_failures\"] = no_label_failed\n",
    "\n",
    "    # save the general parameters values\n",
    "    df_gpam = pd.DataFrame.from_dict(parameter_values, orient=\"index\").T\n",
    "\n",
    "    # instantiate the model\n",
    "    clf, classifier_parameters = clf_function(parameter_sampler_random_int)\n",
    "\n",
    "    # save classifier parameters into dataframe\n",
    "    df_cpam = pd.DataFrame.from_dict(classifier_parameters, orient=\"index\").T\n",
    "\n",
    "    # train the model\n",
    "    try:\n",
    "        result_dict, _, _ = classifier_train_manual(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            df_ymd_only,\n",
    "            train_folds,\n",
    "            clf,\n",
    "            scaler_method=scaler_method,\n",
    "            uo_sample_method=uo_method,\n",
    "            imbalance_ratio=imbalance_ratio,\n",
    "            train_on_all=False,\n",
    "            print_results=False,\n",
    "        )\n",
    "\n",
    "        df_result_dict = pd.DataFrame.from_dict(result_dict, orient=\"index\").T\n",
    "        # df_result_dict.astype(\"float16\").dtypes\n",
    "\n",
    "        if k == 0:\n",
    "            df_results = pd.concat([df_gpam, df_cpam, df_result_dict], axis=1)\n",
    "        else:\n",
    "            df_results = df_results.append(\n",
    "                pd.concat([df_gpam, df_cpam, df_result_dict], axis=1)\n",
    "            )\n",
    "\n",
    "#         # save directory for when on the HPC\n",
    "#         save_directory = Path('/home/tvhahn/scratch/_temp_random_search_results')\n",
    "#         # save_directory = Path(\"/home/tim/Documents/Checkfluid-Project/notebooks/1.9-tvh-feat-table/temp_results\")\n",
    "\n",
    "#         file_save_name = \"temp_result_{}_{}_{}.csv\".format(\n",
    "#             str(date_time), str(sys.argv[1]), str(sampler_seed)\n",
    "#         )\n",
    "#         if k % 10 == 0:\n",
    "#             df_results.to_csv(save_directory / file_save_name, index=False)\n",
    "\n",
    "    except ValueError as err:\n",
    "        print(err)\n",
    "        print(\"#!#!#!#!#! SKIPPING\")\n",
    "        pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# df_results.to_csv(save_directory / file_save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'RandomForestClassifier_bootstrap': False,\n",
       " 'RandomForestClassifier_class_weight': 'balanced',\n",
       " 'RandomForestClassifier_max_depth': 92,\n",
       " 'RandomForestClassifier_min_samples_leaf': 2,\n",
       " 'RandomForestClassifier_n_estimators': 444,\n",
       " 'RandomForestClassifier_random_state': 17678}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "classifier_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_results' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3d5034fa99e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results_1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_results' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_results\n",
    "df.to_csv('results_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df[(df['roc_auc_min']>0.01) & \n",
    "         (df['auc_min']>0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column prefixes\n",
    "col_prefix = ['SGDClassifier', \n",
    "              'KNeighborsClassifier', \n",
    "              'LogisticRegression', \n",
    "              'SVC', \n",
    "              'RidgeClassifier',\n",
    "              'RandomForestClassifier', \n",
    "              'XGB', 'LogisticRegression']\n",
    "\n",
    "primary_cols_sorted = ['clf_name',\n",
    "                         'tool_list',\n",
    "                         'feat_list',\n",
    "                         'indices_to_keep',\n",
    "                         'info_no_samples',\n",
    "                         'info_no_failures',\n",
    "                         'info_no_feat',\n",
    "                         'to_average',\n",
    "                         'uo_method',\n",
    "                         'imbalance_ratio',\n",
    "                         'scaler_method',\n",
    "                         'parameter_sampler_seed',\n",
    "                         'initial_script_seed',\n",
    "                      ]\n",
    "\n",
    "display_table_columns = ['clf_name',\n",
    " 'tool_list',\n",
    " 'feat_list',\n",
    "'parameter_sampler_seed',\n",
    "'initial_script_seed',\n",
    " 'indices_to_keep',\n",
    "'uo_method',\n",
    "'imbalance_ratio',\n",
    "'to_average',\n",
    "'scaler_method',\n",
    " 'auc_max',\n",
    " 'auc_min',\n",
    " 'auc_score',\n",
    " 'auc_std',\n",
    " 'f1_max',\n",
    " 'f1_min',\n",
    " 'f1_score',\n",
    " 'f1_std',\n",
    " 'precision',\n",
    " 'precision_max',\n",
    " 'precision_min',\n",
    " 'precision_std',\n",
    " 'recall',\n",
    " 'recall_max',\n",
    " 'recall_min',\n",
    " 'recall_std',\n",
    " 'roc_auc_max',\n",
    " 'roc_auc_min',\n",
    " 'roc_auc_score',\n",
    " 'roc_auc_std', \n",
    "'train_dates_removed',\n",
    "'auc_min_fold_train','auc_min_fold_test'       \n",
    "]\n",
    "\n",
    "model_parameter_columns = ['RandomForestClassifier_bootstrap',\n",
    "       'RandomForestClassifier_class_weight',\n",
    "       'RandomForestClassifier_max_depth',\n",
    "       'RandomForestClassifier_min_samples_leaf',\n",
    "       'RandomForestClassifier_n_estimators',\n",
    "       'RandomForestClassifier_random_state',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dfr' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-79bcb7021342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clf_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auc_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdisplay_table_columns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_parameter_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auc_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# dfr.to_csv('best_results.csv', index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfr' is not defined"
     ]
    }
   ],
   "source": [
    "dfr = dfr.groupby([\"clf_name\"]).apply(lambda x: x.sort_values([\"auc_score\"], ascending = False)).reset_index(drop=True)\n",
    "dfr = dfr.groupby('clf_name').head(1)[display_table_columns + model_parameter_columns]\n",
    "dfr = dfr.groupby('clf_name').head(1)\n",
    "dfr = dfr.sort_values([\"auc_score\"], ascending = False)\n",
    "# dfr.to_csv('best_results.csv', index=False)\n",
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dfr' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f81c5ba796d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfr' is not defined"
     ]
    }
   ],
   "source": [
    "dfr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_max</th>\n",
       "      <th>auc_min</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>f1_min</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402098</td>\n",
       "      <td>0.304732</td>\n",
       "      <td>0.366959</td>\n",
       "      <td>0.0441237</td>\n",
       "      <td>0.248705</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.187205</td>\n",
       "      <td>0.0438048</td>\n",
       "      <td>0.111855</td>\n",
       "      <td>0.162162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    auc_max   auc_min auc_score    auc_std    f1_max f1_min  f1_score  \\\n",
       "0  0.402098  0.304732  0.366959  0.0441237  0.248705   0.15  0.187205   \n",
       "\n",
       "      f1_std precision precision_max  \n",
       "0  0.0438048  0.111855      0.162162  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr[['auc_max', 'auc_min',\n",
    "       'auc_score', 'auc_std', 'f1_max', 'f1_min', 'f1_score', 'f1_std',\n",
    "       'precision', 'precision_max',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}